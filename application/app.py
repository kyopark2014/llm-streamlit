import streamlit as st 
import chat
import json
import logging
import sys
import time

logger = logging.getLogger()
logger.setLevel(logging.INFO)
# formatter = logging.Formatter('%(asctime)s | %(filename)s:%(lineno)d | %(message)s')
formatter = logging.Formatter('%(message)s')

stdout_handler = logging.StreamHandler(sys.stdout)
stdout_handler.setLevel(logging.INFO)
stdout_handler.setFormatter(formatter)

enableLoggerApp = chat.get_logger_state()
print('enableLoggerApp: ', enableLoggerApp)

if not enableLoggerApp:
    logger.addHandler(stdout_handler)
    try:
        with open("/home/config.json", "r", encoding="utf-8") as f:
            file_handler = logging.FileHandler('/var/log/application/logs.log')
            file_handler.setLevel(logging.INFO)
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)

            logger.info("Ready to write log (app)!")
    except Exception:
        logger.debug(f"Not available to write application log (app)")

st.set_page_config(page_title='AWS', page_icon=None, layout="centered", initial_sidebar_state="auto", menu_items=None)

mode_descriptions = {
    "ì¼ìƒì ì¸ ëŒ€í™”": [
        "ëŒ€í™”ì´ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì±—ë´‡ê³¼ ì¼ìƒì˜ ëŒ€í™”ë¥¼ í¸ì•ˆíˆ ì¦ê¸¸ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ],
    "Agentic Workflow (Tool Use)": [
        "Agentë¥¼ ì´ìš©í•´ ë‹¤ì–‘í•œ íˆ´ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œëŠ” ë‚ ì”¨, ì‹œê°„, ë„ì„œì¶”ì²œ, ì¸í„°ë„· ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤."
    ],
    "Agentic Workflow Chat": [
        "Agentë¥¼ ì´ìš©í•´ ë‹¤ì–‘í•œ íˆ´ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì´ì „ ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ë°˜ì˜í•œ ëŒ€í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    ],
    "ë²ˆì—­í•˜ê¸° (í•œêµ­ì–´ / ì˜ì–´)": [
        "í•œêµ­ì–´ì™€ ì˜ì–´ì— ëŒ€í•œ ë²ˆì—­ì„ ì œê³µí•©ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì…ë ¥í•˜ë©´ ì˜ì–´ë¡œ, ì˜ì–´ë¡œ ì…ë ¥í•˜ë©´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤."        
    ],
    "ë²ˆì—­í•˜ê¸° (ì¼ë³¸ì–´ / í•œêµ­ì–´)": [
        "ì¼ë³¸ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤."        
    ],
    "ë¬¸ë²• ê²€í† í•˜ê¸°": [
        "ì˜ì–´ì™€ í•œêµ­ì–´ ë¬¸ë²•ì˜ ë¬¸ì œì ì„ ì„¤ëª…í•˜ê³ , ìˆ˜ì •ëœ ê²°ê³¼ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤."
    ],
    "ì´ë¯¸ì§€ ë¶„ì„": [
        "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ]
}

with st.sidebar:
    st.title("ğŸ”® Menu")
    
    st.markdown(
        "Amazon Bedrockì„ ì´ìš©í•´ ë‹¤ì–‘í•œ í˜•íƒœì˜ ëŒ€í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤." 
        "ì—¬ê¸°ì—ì„œëŠ” ì¼ìƒì ì¸ ëŒ€í™”ì™€ ê°ì¢… íˆ´ì„ ì´ìš©í•´ Agentë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤." 
        "ë˜í•œ ë²ˆì—­ì´ë‚˜ ë¬¸ë²• í™•ì¸ê³¼ ê°™ì€ ìš©ë„ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        "ì£¼ìš” ì½”ë“œëŠ” LangChainê³¼ LangGraphë¥¼ ì´ìš©í•´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        "ìƒì„¸í•œ ì½”ë“œëŠ” [Github](https://github.com/kyopark2014/llm-streamlit)ì„ ì°¸ì¡°í•˜ì„¸ìš”."
    )

    st.subheader("ğŸ± ëŒ€í™” í˜•íƒœ")
    
    # radio selection
    mode = st.radio(
        label="ì›í•˜ëŠ” ëŒ€í™” í˜•íƒœë¥¼ ì„ íƒí•˜ì„¸ìš”. ",options=["ì¼ìƒì ì¸ ëŒ€í™”", "Agentic Workflow (Tool Use)", "Agentic Workflow Chat", "ë²ˆì—­í•˜ê¸° (í•œêµ­ì–´ / ì˜ì–´)", "ë²ˆì—­í•˜ê¸° (ì¼ë³¸ì–´ / í•œêµ­ì–´)", "ë¬¸ë²• ê²€í† í•˜ê¸°", "ì´ë¯¸ì§€ ë¶„ì„"], index=0
    )   
    st.info(mode_descriptions[mode][0])
    # limit = st.slider(
    #     label="Number of cards",
    #     min_value=1,
    #     max_value=mode_descriptions[mode][2],
    #     value=6,
    # )

    # model selection box
    if mode == 'ì´ë¯¸ì§€ ë¶„ì„':
        index = 3
    else:
        index = 0   
    modelName = st.selectbox(
        'ğŸ–Šï¸ ì‚¬ìš© ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”',
        ('Nova Pro', 'Nova Lite', 'Nova Micro', 'Claude 3.5 Sonnet', 'Claude 3.0 Sonnet', 'Claude 3.5 Haiku'), index=index
    )
    
    uploaded_file = None
    if mode == 'ì´ë¯¸ì§€ ë¶„ì„':
        st.subheader("ğŸŒ‡ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ìš”ì•½ì„ ìœ„í•œ íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.", type=["png", "jpg", "jpeg"])

    # debug checkbox
    select_debugMode = st.checkbox('Debug Mode', value=True)
    debugMode = 'Enable' if select_debugMode else 'Disable'
    # print('debugMode: ', debugMode)

    # multi region check box
    select_multiRegion = st.checkbox('Multi Region', value=False)
    multiRegion = 'Enable' if select_multiRegion else 'Disable'
    #print('multiRegion: ', multiRegion)
   
    chat.update(modelName, debugMode, multiRegion)

    st.success(f"Connected to {modelName}", icon="ğŸ’š")
    clear_button = st.button("ëŒ€í™” ì´ˆê¸°í™”", key="clear")
    # print('clear_button: ', clear_button)

st.title('ğŸ”® '+ mode)

if clear_button==True:
    chat.initiate()

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.greetings = False

# Display chat messages from history on app rerun
def display_chat_messages() -> None:
    """Print message history
    @returns None
    """
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

display_chat_messages()

def show_references(reference_docs):
    if debugMode == "Enable" and reference_docs:
        with st.expander(f"ë‹µë³€ì—ì„œ ì°¸ì¡°í•œ {len(reference_docs)}ê°œì˜ ë¬¸ì„œì…ë‹ˆë‹¤."):
            for i, doc in enumerate(reference_docs):
                st.markdown(f"**{doc.metadata['name']}**: {doc.page_content}")
                st.markdown("---")

# Greet user
if not st.session_state.greetings:
    with st.chat_message("assistant"):
        intro = "ì•„ë§ˆì¡´ ë² ë“œë½ì„ ì´ìš©í•˜ì—¬ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í¸ì•ˆí•œ ëŒ€í™”ë¥¼ ì¦ê¸°ì‹¤ìˆ˜ ìˆìœ¼ë©°, íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìš”ì•½ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        st.markdown(intro)
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": intro})
        st.session_state.greetings = True

if clear_button or "messages" not in st.session_state:
    st.session_state.messages = []        
    uploaded_file = None
    
    st.session_state.greetings = False
    #st.rerun()

    chat.clear_chat_history()

# Preview the uploaded image in the sidebar
file_name = ""
if uploaded_file and clear_button==False and mode == 'ì´ë¯¸ì§€ ë¶„ì„':
    st.image(uploaded_file, caption="ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°", use_container_width=True)

    file_name = uploaded_file.name
    image_url = chat.upload_to_s3(uploaded_file.getvalue(), file_name)
    print('image_url: ', image_url)    
            
# Always show the chat input
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
    logger.info(f"prompt: {prompt}")
    with st.chat_message("user"):  # display user message in chat message container
        st.markdown(prompt)

    st.session_state.messages.append({"role": "user", "content": prompt})  # add user message to chat history
    prompt = prompt.replace('"', "").replace("'", "")
    
    with st.chat_message("assistant"):
        
        if mode == 'ì¼ìƒì ì¸ ëŒ€í™”':
            # with st.status("thinking...", expanded=True, state="running") as status:
            #     stream = chat.general_conversation(prompt)            
            #     response = st.write_stream(stream)
            #     print('response: ', response)
            #     st.session_state.messages.append({"role": "assistant", "content": response})
            #     st.rerun()                

            stream = chat.general_conversation(prompt)            
            response = st.write_stream(stream)            
            logger.info(f"response: {response}")
            
            st.session_state.messages.append({"role": "assistant", "content": response})
            # st.rerun()

        elif mode == 'Agentic Workflow (Tool Use)':
            with st.status("thinking...", expanded=True, state="running") as status:
                response, reference_docs = chat.run_agent_executor(prompt, st)
                # response = chat.run_agent_executor2(prompt st, debugMode, modelName)
                st.write(response)
                print('response: ', response)

                st.session_state.messages.append({"role": "assistant", "content": response})
                if debugMode != "Enable":
                    st.rerun()
            
            show_references(reference_docs) 

        elif mode == 'Agentic Workflow Chat':
            with st.status("thinking...", expanded=True, state="running") as status:
                revise_prompt = chat.revise_question(prompt, st)
                response, reference_docs = chat.run_agent_executor(revise_prompt, st)
                st.write(response)
                print('response: ', response)
                
                st.session_state.messages.append({"role": "assistant", "content": response})
                if debugMode != "Enable":
                    st.rerun()

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 
        elif mode == 'ë²ˆì—­í•˜ê¸° (í•œêµ­ì–´ / ì˜ì–´)':
            response = chat.translate_text(prompt, modelName)
            st.write(response)

            st.session_state.messages.append({"role": "assistant", "content": response})
            # chat.save_chat_history(prompt, response)
        
        elif mode == 'ë²ˆì—­í•˜ê¸° (ì¼ë³¸ì–´ / í•œêµ­ì–´)':
            response = chat.translate_text_for_japanese(prompt, modelName)
            st.write(response)

            st.session_state.messages.append({"role": "assistant", "content": response})
            # chat.save_chat_history(prompt, response)

        elif mode == 'ë¬¸ë²• ê²€í† í•˜ê¸°':
            response = chat.check_grammer(prompt, modelName)
            st.write(response)

            st.session_state.messages.append({"role": "assistant", "content": response})
            # chat.save_chat_history(prompt, response)
        elif mode == 'ì´ë¯¸ì§€ ë¶„ì„':
            if uploaded_file is None or uploaded_file == "":
                st.error("íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
                st.stop()

            else:                
                with st.status("thinking...", expanded=True, state="running") as status:
                    summary = chat.get_image_summarization(file_name, prompt, st)
                    st.write(summary)

                    st.session_state.messages.append({"role": "assistant", "content": summary})
                    if debugMode != "Enable":
                        st.rerun()
        else:
            stream = chat.general_conversation(prompt)

            response = st.write_stream(stream)
            print('response: ', response)

            st.session_state.messages.append({"role": "assistant", "content": response})
            chat.save_chat_history(prompt, response)
        
        
